{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to finish task in episode 0 with reward -200.0 \n",
      "Failed to finish task in episode 1 with reward -200.0 \n",
      "Failed to finish task in episode 2 with reward -200.0 \n",
      "Failed to finish task in episode 3 with reward -200.0 \n",
      "Failed to finish task in episode 4 with reward -200.0 \n",
      "Failed to finish task in episode 5 with reward -200.0 \n",
      "Failed to finish task in episode 6 with reward -200.0 \n",
      "Failed to finish task in episode 7 with reward -200.0 \n",
      "Failed to finish task in episode 8 with reward -200.0 \n",
      "Failed to finish task in episode 9 with reward -200.0 \n",
      "Failed to finish task in episode 10 with reward -200.0 \n",
      "Failed to finish task in episode 11 with reward -200.0 \n",
      "Failed to finish task in episode 12 with reward -200.0 \n",
      "Failed to finish task in episode 13 with reward -200.0 \n",
      "Failed to finish task in episode 14 with reward -200.0 \n",
      "Failed to finish task in episode 15 with reward -200.0 \n",
      "Failed to finish task in episode 16 with reward -200.0 \n",
      "Failed to finish task in episode 17 with reward -200.0 \n",
      "Failed to finish task in episode 18 with reward -200.0 \n",
      "Failed to finish task in episode 19 with reward -200.0 \n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import gym\n",
    "from keras import models\n",
    "from myutils.performanceAnalyzation.Analytics import Analytics\n",
    "import datetime\n",
    "from myutils.trainingClasses.MountainCarConvolutionalTraining import MountainCarConvolutionalTraining as conv_trainor\n",
    "import numpy as np\n",
    "import myutils.constants.Constants as cts\n",
    "\n",
    "\n",
    "analytics = Analytics()\n",
    "env = gym.make('MountainCar-v0').env\n",
    "\n",
    "#play 100 times\n",
    "#load the network\n",
    "time_steps_in_episode = 300\n",
    "episodes = 20\n",
    "model=models.load_model(cts.Constants.PATH_TO_MODELS_OFFLINE_LEARNING+'DQN_CNN_model_interation_520000.h5')\n",
    "\n",
    "stack_depth = 4\n",
    "frame_skip = 4\n",
    "\n",
    "frames_memory = deque(maxlen=stack_depth)\n",
    "\n",
    "for i in range(episodes):\n",
    "\n",
    "    env.reset()\n",
    "\n",
    "    reward_sum=0\n",
    "\n",
    "    current_image =env.render(mode='rgb_array')\n",
    "    current_frame =conv_trainor.process_image(conv_trainor ,current_image)  # the frame is an greyscale image of the current position\n",
    "    current_frame = current_frame.reshape(1, current_frame.shape[0], current_frame.shape[1])\n",
    "    current_state = np.repeat(current_frame,2, axis=0)\n",
    "    frames_memory.extend(current_state)\n",
    "\n",
    "    for t in range(time_steps_in_episode):\n",
    "\n",
    "        if (t% frame_skip) == 0:\n",
    "            current_state = current_state.reshape(1, current_state.shape[0], current_state.shape[1], current_state.shape[2])\n",
    "            best_action = np.argmax(model.predict(current_state)[0])\n",
    "\n",
    "\n",
    "        new_state_numerical, reward, done, _ = env.step(best_action)\n",
    "\n",
    "        new_image = env.render(mode='rgb_array')\n",
    "        next_frame = conv_trainor.process_image(conv_trainor,new_image)\n",
    "        next_frame = next_frame.reshape(next_frame.shape[0], next_frame.shape[1])\n",
    "\n",
    "        # current_state is a FIFO buffer so just by appending the size  of current_state is constant\n",
    "        frames_memory.append(next_frame)\n",
    "\n",
    "        new_state = np.asarray(frames_memory)\n",
    "\n",
    "        # make the training possible only when the minimum experience was gathered\n",
    "\n",
    "        reward_sum += reward\n",
    "        current_state = new_state\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    if t >= time_steps_in_episode - 1:\n",
    "        print(\"Failed to finish task in episode {} with reward {} \".format(i, reward_sum))\n",
    "    else:\n",
    "        print(\"Success in epsoide {}, used {} time steps and obtain reward_sum : {}!\".format(i, t,reward_sum))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% test model predicting actions with convolutional network\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from myutils.performanceAnalyzation.Analytics import Analytics\n",
    "import datetime\n",
    "import myutils.constants.Constants as cts\n",
    "\n",
    "analytics = Analytics()\n",
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "#play 100 times\n",
    "#load the network\n",
    "\n",
    "model=models.load_model(cts.Constants.PATH_TO_MODELS_VALID_SOLUTION+ 'bestTrainNetworkIMountainCar.h5')\n",
    "\n",
    "\n",
    "for i_episode in range(100):\n",
    "    currentState = env.reset().reshape(1, 2)\n",
    "\n",
    "    print(\"============================================\")\n",
    "\n",
    "    rewardSum=0\n",
    "    time_start_episode = datetime.datetime.now()\n",
    "    for t in range(200):\n",
    "        action = np.argmax(model.predict(currentState)[0])\n",
    "\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "\n",
    "        new_state = new_state.reshape(1, 2)\n",
    "\n",
    "        currentState=new_state\n",
    "\n",
    "        rewardSum+=reward\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps reward is {}\".format(t+1,rewardSum))\n",
    "            break\n",
    "\n",
    "    if t >= 199:\n",
    "            print(\"Failed to finish task in epsoide {}\".format(i_episode))\n",
    "    else:\n",
    "        print(\"Success in epsoide {}, used {} iterations!\".format(i_episode, t))\n",
    "\n",
    "    time_end_episode = datetime.datetime.now()\n",
    "    duration_episode = time_end_episode - time_start_episode\n",
    "\n",
    "    analytics.add_info(rewardSum, i_episode, t, duration_episode)\n",
    "print(\"Final testing\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% test model predicting actions without convolutional networks\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
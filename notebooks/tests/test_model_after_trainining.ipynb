{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to finish task in episode 0 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 1 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 2 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 3 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 4 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 5 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 6 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 7 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 8 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 9 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 10 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 11 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 12 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 13 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 14 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 15 with reward -200.0 and epsilon 199\n",
      "Failed to finish task in episode 16 with reward -200.0 and epsilon 199\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-90f2e8d6d9f0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m         \u001B[0mnew_state_numerical\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbest_action\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 43\u001B[1;33m         \u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrender\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     44\u001B[0m         \u001B[0mnext_frame\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconv_trainor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_image\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconv_trainor\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mnew_image\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m         \u001B[0mnext_frame\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext_frame\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnext_frame\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnext_frame\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\lib\\site-packages\\gym\\core.py\u001B[0m in \u001B[0;36mrender\u001B[1;34m(self, mode, **kwargs)\u001B[0m\n\u001B[0;32m    233\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    234\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mrender\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'human'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 235\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrender\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    236\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    237\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\lib\\site-packages\\gym\\envs\\classic_control\\mountain_car.py\u001B[0m in \u001B[0;36mrender\u001B[1;34m(self, mode)\u001B[0m\n\u001B[0;32m    156\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcartrans\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_rotation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcos\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mpos\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    157\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 158\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mviewer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrender\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreturn_rgb_array\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m==\u001B[0m\u001B[1;34m'rgb_array'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    159\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    160\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_keys_to_action\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001B[0m in \u001B[0;36mrender\u001B[1;34m(self, return_rgb_array)\u001B[0m\n\u001B[0;32m    112\u001B[0m             \u001B[0marr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbuffer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mheight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwidth\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    113\u001B[0m             \u001B[0marr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marr\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 114\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwindow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    115\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0monetime_geoms\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0marr\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mreturn_rgb_array\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misopen\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001B[0m in \u001B[0;36mflip\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    319\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mflip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    320\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdraw_mouse_cursor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 321\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    322\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    323\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mset_location\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\lib\\site-packages\\pyglet\\gl\\win32.py\u001B[0m in \u001B[0;36mflip\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    224\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mflip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 226\u001B[1;33m         \u001B[0m_gdi32\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSwapBuffers\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcanvas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhdc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    227\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    228\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_vsync\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import gym\n",
    "from keras import models\n",
    "from myutils.performanceAnalyzation.Analytics import Analytics\n",
    "import datetime\n",
    "from myutils.trainingClasses.MountainCarConvolutionalTraining import MountainCarConvolutionalTraining as conv_trainor\n",
    "import numpy as np\n",
    "import myutils.constants.Constants as cts\n",
    "\n",
    "\n",
    "analytics = Analytics()\n",
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "#play 100 times\n",
    "#load the network\n",
    "time_steps_in_episode = 200\n",
    "episodes = 100\n",
    "model=models.load_model(cts.Constants.PATH_TO_MODELS_OFFLINE_LEARNING+'DQN_CNN_model_interation_5000.h5')\n",
    "\n",
    "frames_memory = deque(maxlen=2)\n",
    "\n",
    "for i in range(episodes):\n",
    "\n",
    "    env.reset()\n",
    "\n",
    "    reward_sum=0\n",
    "\n",
    "    current_image =env.render(mode='rgb_array')\n",
    "    current_frame =conv_trainor.process_image(conv_trainor ,current_image)  # the frame is an greyscale image of the current position\n",
    "    current_frame = current_frame.reshape(1, current_frame.shape[0], current_frame.shape[1])\n",
    "    current_state = np.repeat(current_frame,2, axis=0)\n",
    "    frames_memory.extend(current_state)\n",
    "    new_image = env.render(mode='rgb_array')\n",
    "\n",
    "    for t in range(time_steps_in_episode):\n",
    "\n",
    "        current_state = current_state.reshape(1, current_state.shape[0], current_state.shape[1], current_state.shape[2])\n",
    "        best_action = np.argmax(model.predict(current_state)[0])\n",
    "\n",
    "\n",
    "        new_state_numerical, reward, done, _ = env.step(best_action)\n",
    "        env.render()\n",
    "        next_frame = conv_trainor.process_image(conv_trainor,new_image)\n",
    "        next_frame = next_frame.reshape(next_frame.shape[0], next_frame.shape[1])\n",
    "\n",
    "        # current_state is a FIFO buffer so just by appending the size  of current_state is constant\n",
    "        frames_memory.append(next_frame)\n",
    "\n",
    "        new_state = np.asarray(frames_memory)\n",
    "\n",
    "        # make the training possible only when the minimum experience was gathered\n",
    "\n",
    "        reward_sum += reward\n",
    "        current_state = new_state\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    if t >= time_steps_in_episode - 1:\n",
    "        print(\"Failed to finish task in episode {} with reward {} and epsilon {}\".format(i, reward_sum,\n",
    "                                                                                         t))\n",
    "    else:\n",
    "        print(\"Success in epsoide {}, used {} time steps and obtain reward_sum : {}!\".format(i, t,reward_sum))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% test model predicting actions with convolutional network\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from myutils.performanceAnalyzation.Analytics import Analytics\n",
    "import datetime\n",
    "import myutils.constants.Constants as cts\n",
    "\n",
    "analytics = Analytics()\n",
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "#play 100 times\n",
    "#load the network\n",
    "\n",
    "model=models.load_model(cts.Constants.PATH_TO_MODELS_VALID_SOLUTION+ 'bestTrainNetworkIMountainCar.h5')\n",
    "\n",
    "\n",
    "for i_episode in range(100):\n",
    "    currentState = env.reset().reshape(1, 2)\n",
    "\n",
    "    print(\"============================================\")\n",
    "\n",
    "    rewardSum=0\n",
    "    time_start_episode = datetime.datetime.now()\n",
    "    for t in range(200):\n",
    "        action = np.argmax(model.predict(currentState)[0])\n",
    "\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "\n",
    "        new_state = new_state.reshape(1, 2)\n",
    "\n",
    "        currentState=new_state\n",
    "\n",
    "        rewardSum+=reward\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps reward is {}\".format(t+1,rewardSum))\n",
    "            break\n",
    "\n",
    "    if t >= 199:\n",
    "            print(\"Failed to finish task in epsoide {}\".format(i_episode))\n",
    "    else:\n",
    "        print(\"Success in epsoide {}, used {} iterations!\".format(i_episode, t))\n",
    "\n",
    "    time_end_episode = datetime.datetime.now()\n",
    "    duration_episode = time_end_episode - time_start_episode\n",
    "\n",
    "    analytics.add_info(rewardSum, i_episode, t, duration_episode)\n",
    "print(\"Final testing\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% test model predicting actions without convolutional networks\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}